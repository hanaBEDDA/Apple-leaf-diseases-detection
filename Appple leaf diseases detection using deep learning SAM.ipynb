{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpAdbSkB86k3",
    "outputId": "1946b9a2-dccd-489f-ab3d-86f2eac55733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting opendatasets\n",
      "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.15)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
      "Installing collected packages: opendatasets\n",
      "Successfully installed opendatasets-0.1.22\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jEGoOgbYl1Rj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import opendatasets as od\n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fF72Hg1KEDp0",
    "outputId": "b2bc5687-4817-4897-9cee-b3f7d39297b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: beddahana\n",
      "Your Kaggle Key: ··········\n",
      "Downloading plant-pathology-2020-fgvc7.zip to ./plant-pathology-2020-fgvc7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 779M/779M [00:12<00:00, 67.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting archive ./plant-pathology-2020-fgvc7/plant-pathology-2020-fgvc7.zip to ./plant-pathology-2020-fgvc7\n"
     ]
    }
   ],
   "source": [
    "dataset = od.download(\n",
    "    \"https://www.kaggle.com/competitions/plant-pathology-2020-fgvc7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5w_rocnEDtu",
    "outputId": "de4a02f8-6eb6-4598-9985-d067dbb2c8aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu118\n",
      "Torchvision version: 0.15.2+cu118\n",
      "CUDA is available: True\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
      "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-5mv7v5wh\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-5mv7v5wh\n",
      "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: segment-anything\n",
      "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36589 sha256=95f66ec612ed80604d39b7dc11fd8b55cf6d13ce7b38bee594338e9f551e21e0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p92wyoet/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
      "Successfully built segment-anything\n",
      "Installing collected packages: segment-anything\n",
      "Successfully installed segment-anything-1.0\n",
      "--2023-06-14 19:26:50--  https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99846 (98K) [image/jpeg]\n",
      "Saving to: ‘images/dog.jpg’\n",
      "\n",
      "dog.jpg             100%[===================>]  97.51K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2023-06-14 19:26:51 (9.97 MB/s) - ‘images/dog.jpg’ saved [99846/99846]\n",
      "\n",
      "--2023-06-14 19:26:51--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.224.2.6, 13.224.2.42, 13.224.2.88, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.224.2.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2564550879 (2.4G) [binary/octet-stream]\n",
      "Saving to: ‘sam_vit_h_4b8939.pth’\n",
      "\n",
      "sam_vit_h_4b8939.pt 100%[===================>]   2.39G   234MB/s    in 10s     \n",
      "\n",
      "2023-06-14 19:27:01 (235 MB/s) - ‘sam_vit_h_4b8939.pth’ saved [2564550879/2564550879]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python matplotlib\n",
    "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "!mkdir images\n",
    "!wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-NxljHsk9YLp"
   },
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GovPxIvO99P9"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"/content/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=32,\n",
    "    pred_iou_thresh=0.86,\n",
    "    stability_score_thresh=0.92,\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K03f7HJf-GS_"
   },
   "outputs": [],
   "source": [
    "image_dir = \"/content/plant-pathology-2020-fgvc7/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3t2mWtvk-v7z"
   },
   "outputs": [],
   "source": [
    "output_dir = \"/content/output/SAMimages\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vm60aOU-_BCR"
   },
   "outputs": [],
   "source": [
    "# Iterate over the images in the directory and apply the segment anything model to each image\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "for filename in os.listdir(image_dir):\n",
    "    if not filename.endswith(\".jpg\"):\n",
    "        continue\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Generate the masks using the mask generator\n",
    "    masks = mask_generator.generate(image)\n",
    "\n",
    "   # overlay masks on the original image\n",
    "    image_with_masks = image.copy()\n",
    "    #for mask in masks:\n",
    "     #   image_with_masks = cv2.addWeighted(image_with_masks, 1, mask, 0.5, 0)\n",
    "\n",
    "    # save the output image\n",
    "    output_filename = os.path.join(output_dir, filename)\n",
    "    cv2.imwrite(output_filename, image_with_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pHePIBY_K2F"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
